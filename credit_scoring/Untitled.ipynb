{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2815\n1     136\nName: плохой_клиент, dtype: int64\n0    104956\n1      7544\nName: плохой_клиент, dtype: int64\n(112500, 11) (37500, 10)\nIndex(['линии', 'возраст', 'поведение_30-59_дней', 'Debt_Ratio', 'доход',\n       'число_кредитов', 'поведение_90_дней', 'недвижимость',\n       'поведение_60-89_дней', 'семья'],\n      dtype='object')\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 112500 entries, 0 to 112499\nData columns (total 10 columns):\nлинии                   112500 non-null float64\nвозраст                 112500 non-null int64\nповедение_30-59_дней    112500 non-null int64\nDebt_Ratio              112500 non-null float64\nдоход                   90274 non-null float64\nчисло_кредитов          112500 non-null int64\nповедение_90_дней       112500 non-null int64\nнедвижимость            112500 non-null int64\nповедение_60-89_дней    112500 non-null int64\nсемья                   109549 non-null float64\ndtypes: float64(4), int64(6)\nmemory usage: 8.6 MB\nNone\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 37500 entries, 0 to 37499\nData columns (total 10 columns):\nлинии                   37500 non-null float64\nвозраст                 37500 non-null int64\nповедение_30-59_дней    37500 non-null int64\nDebt_Ratio              37500 non-null float64\nдоход                   29995 non-null float64\nчисло_кредитов          37500 non-null int64\nповедение_90_дней       37500 non-null int64\nнедвижимость            37500 non-null int64\nповедение_60-89_дней    37500 non-null int64\nсемья                   36527 non-null float64\ndtypes: float64(4), int64(6)\nmemory usage: 2.9 MB\nNone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6662.379910051621 6693.8207701283545\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.style.use('seaborn-dark')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib as plt\n",
    "plt.rc('font', size=14)\n",
    "\n",
    "def plot_2d_separator(classifier, X, fill=False, line=True, ax=None, eps=None):\n",
    "    if eps is None:\n",
    "        \n",
    "        eps = 1.0\n",
    "    x_min, x_max = X[:, 0].min() - eps, X[:, 0].max() + eps\n",
    "    y_min, y_max = X[:, 1].min() - eps, X[:, 1].max() + eps\n",
    "    xx = np.linspace(x_min, x_max, 100)\n",
    "    yy = np.linspace(y_min, y_max, 100)\n",
    "    \n",
    "    X1, X2 = np.meshgrid(xx, yy)\n",
    "    X_grid = np.c_[X1.ravel(), X2.ravel()]\n",
    "    try:\n",
    "        decision_values = classifier.decision_function(X_grid)\n",
    "        levels = [0]\n",
    "        fill_levels = [decision_values.min(), 0, decision_values.max()]\n",
    "    except:\n",
    "        decision_values = classifier.predict_proba(X_grid)[:, 1]\n",
    "        levels = [.5]\n",
    "        fill_levels = [0, .5, 1]\n",
    "        \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    if fill:\n",
    "        ax.contourf(X1, X2, decision_values.reshape(X1.shape),\n",
    "                    levels=fill_levels, colors=['cyan', 'pink'])\n",
    "    if line:\n",
    "        ax.contour(X1, X2, decision_values.reshape(X1.shape), levels=levels,\n",
    "                   colors=\"black\")\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "## Загружаем данные\n",
    "\n",
    "train = pd.read_csv('/home/paniquex/PycharmProjects/IML_homeworks/credit_scoring/train.csv')\n",
    "test = pd.read_csv('/home/paniquex/PycharmProjects/IML_homeworks/credit_scoring/test.csv')\n",
    "print(train['плохой_клиент'][train['семья'].isna()].value_counts())\n",
    "print(train['плохой_клиент'].value_counts())\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "y = train.pop('плохой_клиент')\n",
    "train.shape, y.shape\n",
    "\n",
    "## Предобработка\n",
    "\n",
    "## Очень много пропусков в доходе: \n",
    "\n",
    "print(train.columns)\n",
    "print(train.info())\n",
    "\n",
    "print(test.info())\n",
    "\n",
    "## Интересный человек №21595\n",
    "\n",
    "train.sort_values(by='недвижимость', ascending=False).head()\n",
    "\n",
    "train.describe()\n",
    "\n",
    "train['доход'][train[\"доход\"] < 1].value_counts()\n",
    "\n",
    "## Заполним пропуски в доходе средним значением по всей таблице, а значение семьи = 0 \n",
    "\n",
    "train.sort_values(by='доход', ascending=False).head(10)\n",
    "\n",
    "mean_income_train = train['доход'].mean()\n",
    "mean_income_test = test['доход'].mean()\n",
    "print(mean_income_train, mean_income_test)\n",
    "train['доход'].fillna(mean_income_train, inplace=True)\n",
    "test['доход'].fillna(mean_income_test, inplace=True)\n",
    "\n",
    "### Семья\n",
    "\n",
    "train['семья'].fillna(1, inplace=True)\n",
    "test['семья'].fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "class DjStacking(BaseEstimator, ClassifierMixin):  \n",
    "    \"\"\"Стэкинг моделей scikit-learn\"\"\"\n",
    "\n",
    "    def __init__(self, models, ens_model):\n",
    "        \"\"\"\n",
    "        Инициализация\n",
    "        models - базовые модели для стекинга\n",
    "        ens_model - мета-модель\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "        self.ens_model = ens_model\n",
    "        self.n = len(models)\n",
    "        self.valid = None\n",
    "        \n",
    "    def fit(self, X, y=None, p=0.25, cv=3, err=0.001, random_state=None):\n",
    "        \"\"\"\n",
    "        Обучение стекинга\n",
    "        p - в каком отношении делить на обучение / тест\n",
    "            если p = 0 - используем всё обучение!\n",
    "        cv  (при p=0) - сколько фолдов использовать\n",
    "        err (при p=0) - величина случайной добавки к метапризнакам\n",
    "        random_state - инициализация генератора\n",
    "            \n",
    "        \"\"\"\n",
    "        if (p > 0): # делим на обучение и тест\n",
    "            # разбиение на обучение моделей и метамодели\n",
    "            train, valid, y_train, y_valid = train_test_split(X, y, test_size=p, random_state=random_state)\n",
    "            \n",
    "            # заполнение матрицы для обучения метамодели\n",
    "            self.valid = np.zeros((valid.shape[0], self.n))\n",
    "            for t, clf in enumerate(self.models):\n",
    "                clf.fit(train, y_train)\n",
    "                self.valid[:, t] = clf.predict(valid)\n",
    "                \n",
    "            # обучение метамодели\n",
    "            self.ens_model.fit(self.valid, y_valid)\n",
    "            \n",
    "        else: # используем всё обучение\n",
    "            \n",
    "            # для регуляризации - берём случайные добавки\n",
    "            self.valid = err*np.random.randn(X.shape[0], self.n)\n",
    "            \n",
    "            for t, clf in enumerate(self.models):\n",
    "                # это oob-ответы алгоритмов\n",
    "                self.valid[:, t] += cross_val_predict(clf, X, y, cv=cv, n_jobs=-1, method='predict')\n",
    "                # но сам алгоритм надо настроить\n",
    "                clf.fit(X, y)\n",
    "            \n",
    "            # обучение метамодели\n",
    "            self.ens_model.fit(self.valid, y)  \n",
    "            \n",
    "\n",
    "        return self\n",
    "    \n",
    "\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Работа стэкинга\n",
    "        \"\"\"\n",
    "        # заполение матрицы для мета-классификатора\n",
    "        X_meta = np.zeros((X.shape[0], self.n))\n",
    "        \n",
    "        for t, clf in enumerate(self.models):\n",
    "            X_meta[:, t] = clf.predict(X)\n",
    "        \n",
    "        a = self.ens_model.predict(X_meta)\n",
    "        \n",
    "        return (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "strCV = StratifiedKFold(n_splits = 5, random_state = 10)\n",
    "model_rand_forest_line = RandomForestClassifier(n_estimators = 40)\n",
    "rand_forest_line_grid_param = {'max_depth' : range(8, 14), 'max_features' : range(3, 9), \n",
    "                               'criterion' : ['entropy'], \n",
    "                              'min_samples_split': [30],\n",
    "                              'min_samples_leaf' : [30],\n",
    "                               'min_impurity_decrease' : [0.00001, 0.0004, 0.1],\n",
    "                                'min_weight_fraction_leaf' : [0.00005, 0.0001, 0.01],\n",
    "                                 'min_impurity_split' : [0.00004, 0.1, 0.001, 1, 0.0001]\n",
    "                              }\n",
    "                                            \n",
    "model_rand_forest_line_grid = GridSearchCV(estimator=model_rand_forest_line, param_grid=rand_forest_line_grid_param, cv=strCV, verbose=1, n_jobs=-1)\n",
    "#model_rand_forest_line_grid.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight={1: 1, 0: 3},\n            criterion='entropy', max_depth=8, max_features=5,\n            max_leaf_nodes=None, min_impurity_decrease=1e-05,\n            min_impurity_split=0.001, min_samples_leaf=30,\n            min_samples_split=30, min_weight_fraction_leaf=0.0001,\n            n_estimators=250, n_jobs=1, oob_score=False, random_state=20,\n            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_rand_forest_line_grid.best_params_\n",
    "# {'criterion': 'entropy',\n",
    "#  'max_depth': 8,\n",
    "#  'max_features': 5,\n",
    "#  'min_impurity_decrease': 1e-05,\n",
    "#  'min_impurity_split': 0.001,\n",
    "#  'min_samples_leaf': 30,\n",
    "#  'min_samples_split': 30,\n",
    "#  'min_weight_fraction_leaf': 0.0001}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, y, test_size = 0.8, random_state = 20)\n",
    "\n",
    "model_rand_forest_new = RandomForestClassifier(n_estimators=250, criterion= 'entropy', min_impurity_decrease=1e-05,\n",
    " min_weight_fraction_leaf = 0.0001,\n",
    " min_impurity_split = 0.001,\n",
    " max_depth= 8,\n",
    " max_features= 5,\n",
    " class_weight = {1 : 1, 0 : 3},\n",
    " min_samples_leaf= 30,\n",
    " min_samples_split= 30,\n",
    " oob_score= False,\n",
    " random_state = 20)\n",
    "model_rand_forest_new.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-623346aa089b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"False Positive Rate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"True Positive Rate (recall)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mfpr9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_rand_forest_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mauc9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_rand_forest_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m plt.plot(fpr9, tpr9, label=(\"auc=%.4f\" % auc9), linewidth=2,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ],
     "output_type": "error"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 8, 5\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate (recall)\")\n",
    "fpr9, tpr9, _= roc_curve(y_test, model_rand_forest_new.predict_proba(X_test)[:, 1] )\n",
    "auc9 = roc_auc_score(y_test, model_rand_forest_new.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr9, tpr9, label=(\"auc=%.4f\" % auc9), linewidth=2,\n",
    "color='#990000')\n",
    "plt.legend(loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_rand_forest = RandomForestClassifier(n_estimators=150, criterion= 'entropy', min_impurity_decrease=0.00001,\n",
    " min_weight_fraction_leaf = 0.00005,\n",
    " min_impurity_split = 0.00004,\n",
    " max_depth= 9,\n",
    " max_features= 4,\n",
    " class_weight = {1:4, 0:1},\n",
    " min_samples_leaf= 30,\n",
    " min_samples_split= 30,\n",
    " oob_score= False,\n",
    " random_state = 20)\n",
    "\n",
    "train_with_new_features =  train.copy()\n",
    "train_log_reg_data = train_with_new_features.copy()\n",
    "##большие значения у линий - выбросы, уберем их\n",
    "\n",
    "\n",
    "\n",
    "train_log_reg_data['линии'][train_log_reg_data['линии'] >= 10] = 1\n",
    "feature_1 = (train_log_reg_data['поведение_30-59_дней'] >= 1) #| (train_log_reg_data['поведение_60-89_дней'] >= 1) \\\n",
    "#             | (train_log_reg_data['поведение_90_дней'] >= 1)\n",
    "train_log_reg_data['feature_1'] = feature_1\n",
    "train_log_reg_data['поведение_90_дней'][train_log_reg_data['поведение_90_дней'] > 35] = 1\n",
    "train_log_reg_data['поведение_60-89_дней'][train_log_reg_data['поведение_60-89_дней'] > 35] = 1\n",
    "train_log_reg_data['поведение_30-59_дней'][train_log_reg_data['поведение_30-59_дней'] > 35] = 1\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "feature_2 = (train_log_reg_data['недвижимость'] >= 1) \n",
    "train_log_reg_data['feature_2'] = feature_2\n",
    "\n",
    "feature_3 = (train_log_reg_data['число_кредитов'] >= 15)\n",
    "train_log_reg_data['feature_3'] = feature_3\n",
    "# \n",
    "feature_4 = (train_log_reg_data['доход'] <= train_log_reg_data['доход'].quantile(q=0.35))\n",
    "train_log_reg_data['feature_4'] = feature_4\n",
    "\n",
    "feature_5 = (train_log_reg_data['Debt_Ratio'] <= train_log_reg_data['Debt_Ratio'].quantile(q=0.5))\n",
    "train_log_reg_data['feature_5'] = feature_5\n",
    "\n",
    "feature_6 = (train_log_reg_data['линии'] <= train_log_reg_data['линии'].quantile(q=0.05))\n",
    "train_log_reg_data['feature_6'] = feature_6\n",
    "\n",
    "feature_7 = (train_log_reg_data['поведение_60-89_дней'] >= 1)\n",
    "train_log_reg_data['feature_7'] = feature_7\n",
    "\n",
    "feature_8 = (train_log_reg_data['поведение_90_дней'] >= 1)\n",
    "train_log_reg_data['feature_8'] = feature_8\n",
    "\n",
    "feature_9 = (train_log_reg_data['возраст'] >= train_log_reg_data['возраст'].quantile(q=0.6))\n",
    "train_log_reg_data['feature_9'] = feature_9\n",
    "\n",
    "feature_10 = (3*train_log_reg_data['поведение_60-89_дней'] + train_log_reg_data['поведение_30-59_дней']) > train_log_reg_data['поведение_90_дней']\n",
    "train_log_reg_data['feature_10'] = feature_10\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#col_names = ['линии', 'доход', 'Debt_Ratio']\n",
    "#features = train_log_reg_data[col_names]\n",
    "#features = StandardScaler().fit_transform(features)\n",
    "#train_log_reg_data[col_names] = features\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_log_reg_data, y, train_size = 0.2, random_state=20)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "passiveAggre = GradientBoostingClassifier(loss='exponential',learning_rate=0.1,  min_impurity_decrease=0.00001,\n",
    " min_weight_fraction_leaf = 0.00005,\n",
    " min_impurity_split = 0.00004,\n",
    " max_depth= 4,\n",
    " max_features= 4,\n",
    " min_samples_leaf= 30,\n",
    " min_samples_split= 3,\n",
    " random_state = 20)\n",
    "rand_forest_line_grid_param = {'max_depth' : range(2, 7), 'max_features' : range(3, 7),\n",
    "                               'learning_rate' : [1, 0.1, 0.01],\n",
    "                               'loss' : ['exponential', 'deviance'], \n",
    "                              'min_samples_split': [30],\n",
    "                              'min_samples_leaf' : [30],\n",
    "                               'min_impurity_decrease' : [0.00001, 0.1],\n",
    "                                'min_weight_fraction_leaf' : [0.00005, 0.01],\n",
    "                                 'min_impurity_split' : [0.00004, 0.001, 1, 0.0001]\n",
    "                              }\n",
    "strCV = StratifiedKFold(n_splits = 4, random_state = 10)                                            \n",
    "#model_boosting_forest_line_grid = GridSearchCV(estimator=passiveAggre, param_grid=rand_forest_line_grid_param, cv=strCV, verbose=1, n_jobs=-1)\n",
    "#model_boosting_forest_line_grid.fit(train_log_reg_data, y)\n",
    "\n",
    "#model_rand_forest.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_boosting_forest_line_grid' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8a194d20ddc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_boosting_forest_line_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m {'learning_rate': 0.1,\n\u001b[1;32m      3\u001b[0m  \u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'exponential'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m  \u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m  \u001b[0;34m'max_features'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_boosting_forest_line_grid' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "model_boosting_forest_line_grid.best_params_\n",
    "{'learning_rate': 0.1,\n",
    " 'loss': 'exponential',\n",
    " 'max_depth': 5,\n",
    " 'max_features': 4,\n",
    " 'min_impurity_decrease': 0.1,\n",
    " 'min_impurity_split': 4e-05,\n",
    " 'min_samples_leaf': 30,\n",
    " 'min_samples_split': 30,\n",
    " 'min_weight_fraction_leaf': 5e-05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_new_features =  train.copy()\n",
    "train_log_reg_data = train_with_new_features.copy()\n",
    "##большие значения у линий - выбросы, уберем их\n",
    "\n",
    "\n",
    "train_log_reg_data['Debt_Ratio'][train_log_reg_data['Debt_Ratio'] >= train_log_reg_data['Debt_Ratio'].quantile(q=0.995)] = train_log_reg_data['Debt_Ratio'].quantile(q=0.5)\n",
    "train_log_reg_data['Debt_Ratio'][train_log_reg_data['Debt_Ratio'] <= train_log_reg_data['Debt_Ratio'].quantile(q=0.005)] = train_log_reg_data['Debt_Ratio'].quantile(q=0.5)\n",
    "train_log_reg_data['доход'][train_log_reg_data['доход'] >= train_log_reg_data['доход'].quantile(q=0.995)] = train_log_reg_data['доход'].quantile(q=0.5)\n",
    "train_log_reg_data['линии'][(train_log_reg_data['линии'] >= 10)] = 0.3\n",
    "train_log_reg_data['доход'][train_log_reg_data['доход'] > train_log_reg_data['доход'].quantile(q=0.85)] = train_log_reg_data['доход'].quantile(q=0.4)\n",
    "train_log_reg_data['Debt_Ratio'][train_log_reg_data['Debt_Ratio'] > train_log_reg_data['Debt_Ratio'].quantile(q=0.8)] = train_log_reg_data['Debt_Ratio'].quantile(q=0.4)\n",
    "\n",
    "feature_1 = (train_log_reg_data['поведение_30-59_дней'] >= 1) #| (train_log_reg_data['поведение_60-89_дней'] >= 1) \\\n",
    "            # | (train_log_reg_data['поведение_90_дней'] >= 1)\n",
    "train_log_reg_data['feature_1'] = feature_1\n",
    "train_log_reg_data['поведение_90_дней'][train_log_reg_data['поведение_90_дней'] > 35] = 1\n",
    "train_log_reg_data['поведение_60-89_дней'][train_log_reg_data['поведение_60-89_дней'] > 35] = 1\n",
    "train_log_reg_data['поведение_30-59_дней'][train_log_reg_data['поведение_30-59_дней'] > 35] = 1\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "feature_2 = (train_log_reg_data['недвижимость'] >= 1) \n",
    "train_log_reg_data['feature_2'] = feature_2\n",
    "\n",
    "feature_3 = (train_log_reg_data['число_кредитов'] >= 15)\n",
    "train_log_reg_data['feature_3'] = feature_3\n",
    "\n",
    "feature_4 = (train_log_reg_data['доход'] <= train_log_reg_data['доход'].quantile(q=0.35))\n",
    "train_log_reg_data['feature_4'] = feature_4\n",
    "\n",
    "feature_5 = (train_log_reg_data['Debt_Ratio'] <= train_log_reg_data['Debt_Ratio'].quantile(q=0.5))\n",
    "train_log_reg_data['feature_5'] = feature_5\n",
    "\n",
    "feature_6 = (train_log_reg_data['линии'] <= train_log_reg_data['линии'].quantile(q=0.05))\n",
    "train_log_reg_data['feature_6'] = feature_6\n",
    "\n",
    "feature_7 = (train_log_reg_data['поведение_60-89_дней'] >= 1)\n",
    "train_log_reg_data['feature_7'] = feature_7\n",
    "\n",
    "feature_8 = (train_log_reg_data['поведение_90_дней'] >= 1)\n",
    "train_log_reg_data['feature_8'] = feature_8\n",
    "\n",
    "feature_9 = (train_log_reg_data['возраст'] >= train_log_reg_data['возраст'].quantile(q=0.6))\n",
    "train_log_reg_data['feature_9'] = feature_9\n",
    "\n",
    "feature_10 = (3*train_log_reg_data['поведение_60-89_дней'] + 5 * train_log_reg_data['поведение_30-59_дней']) > train_log_reg_data['поведение_90_дней']\n",
    "train_log_reg_data['feature_10'] = feature_10\n",
    "\n",
    "feature_11 = np.log2(train_log_reg_data['линии']+ 0.00001)\n",
    "train_log_reg_data['feature_11'] = feature_11\n",
    "# \n",
    "# \n",
    "test_log_reg_data = test.copy()\n",
    "test_log_reg_data['Debt_Ratio'][test_log_reg_data['Debt_Ratio'] >= test_log_reg_data['Debt_Ratio'].quantile(q=0.995)] = test_log_reg_data['Debt_Ratio'].quantile(q=0.5)\n",
    "test_log_reg_data['Debt_Ratio'][test_log_reg_data['Debt_Ratio'] <= test_log_reg_data['Debt_Ratio'].quantile(q=0.005)] = test_log_reg_data['Debt_Ratio'].quantile(q=0.5)\n",
    "test_log_reg_data['доход'][test_log_reg_data['доход'] >= test_log_reg_data['доход'].quantile(q=0.995)] = test_log_reg_data['доход'].quantile(q=0.5)\n",
    "test_log_reg_data['линии'][(test_log_reg_data['линии'] >= 10)] = 0.3\n",
    "test_log_reg_data['доход'][test_log_reg_data['доход'] > test_log_reg_data['доход'].quantile(q=0.85)] = test_log_reg_data['доход'].quantile(q=0.4)\n",
    "test_log_reg_data['Debt_Ratio'][test_log_reg_data['Debt_Ratio'] > test_log_reg_data['Debt_Ratio'].quantile(q=0.8)] = test_log_reg_data['Debt_Ratio'].quantile(q=0.4)\n",
    "\n",
    "feature_1 = (test_log_reg_data['поведение_30-59_дней'] >= 1) #| (test_log_reg_data['поведение_60-89_дней'] >= 1) \\\n",
    "            # | (test_log_reg_data['поведение_90_дней'] >= 1)\n",
    "test_log_reg_data['feature_1'] = feature_1\n",
    "test_log_reg_data['поведение_90_дней'][test_log_reg_data['поведение_90_дней'] > 35] = 1\n",
    "test_log_reg_data['поведение_60-89_дней'][test_log_reg_data['поведение_60-89_дней'] > 35] = 1\n",
    "test_log_reg_data['поведение_30-59_дней'][test_log_reg_data['поведение_30-59_дней'] > 35] = 1\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "feature_2 = (test_log_reg_data['недвижимость'] >= 1) \n",
    "test_log_reg_data['feature_2'] = feature_2\n",
    "\n",
    "feature_3 = (test_log_reg_data['число_кредитов'] >= 15)\n",
    "test_log_reg_data['feature_3'] = feature_3\n",
    "\n",
    "feature_4 = (test_log_reg_data['доход'] <= test_log_reg_data['доход'].quantile(q=0.35))\n",
    "test_log_reg_data['feature_4'] = feature_4\n",
    "\n",
    "feature_5 = (test_log_reg_data['Debt_Ratio'] <= test_log_reg_data['Debt_Ratio'].quantile(q=0.5))\n",
    "test_log_reg_data['feature_5'] = feature_5\n",
    "\n",
    "feature_6 = (test_log_reg_data['линии'] <= test_log_reg_data['линии'].quantile(q=0.05))\n",
    "test_log_reg_data['feature_6'] = feature_6\n",
    "\n",
    "feature_7 = (test_log_reg_data['поведение_60-89_дней'] >= 1)\n",
    "test_log_reg_data['feature_7'] = feature_7\n",
    "\n",
    "feature_8 = (test_log_reg_data['поведение_90_дней'] >= 1)\n",
    "test_log_reg_data['feature_8'] = feature_8\n",
    "\n",
    "feature_9 = (test_log_reg_data['возраст'] >= test_log_reg_data['возраст'].quantile(q=0.6))\n",
    "test_log_reg_data['feature_9'] = feature_9\n",
    "\n",
    "feature_10 = (3*test_log_reg_data['поведение_60-89_дней'] + 5 * test_log_reg_data['поведение_30-59_дней']) > test_log_reg_data['поведение_90_дней']\n",
    "test_log_reg_data['feature_10'] = feature_10\n",
    "\n",
    "feature_11 = np.log2(test_log_reg_data['линии']+ 0.00001)\n",
    "test_log_reg_data['feature_11'] = feature_11\n",
    "# \n",
    "# \n",
    "# \n",
    "# train_log_reg_data['линии'][train_log_reg_data['линии'] >= train_log_reg_data['линии'].quantile(q=0.995)] = train_log_reg_data['линии'].quantile(q=0.5)\n",
    "# train_log_reg_data['число_кредитов'][train_log_reg_data['число_кредитов'] >= train_log_reg_data['число_кредитов'].quantile(q=0.995)] = train_log_reg_data['число_кредитов'].quantile(q=0.5)\n",
    "# train_log_reg_data['поведение_30-59_дней'][train_log_reg_data['поведение_30-59_дней'] >= train_log_reg_data['поведение_30-59_дней'].quantile(q=0.995)] = train_log_reg_data['поведение_30-59_дней'].quantile(q=0.5)\n",
    "# train_log_reg_data['поведение_60-89_дней'][train_log_reg_data['поведение_60-89_дней'] >= train_log_reg_data['поведение_60-89_дней'].quantile(q=0.995)] = train_log_reg_data['поведение_60-89_дней'].quantile(q=0.5)\n",
    "# train_log_reg_data['поведение_90_дней'][train_log_reg_data['поведение_90_дней'] >= train_log_reg_data['поведение_90_дней'].quantile(q=0.995)] = train_log_reg_data['поведение_90_дней'].quantile(q=0.5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train_log_reg_data['линии'][train_log_reg_data['линии'] >= 10] = 0\n",
    "# feature_1 = (train_log_reg_data['поведение_30-59_дней'] >= 2) | (train_log_reg_data['поведение_60-89_дней'] >= 2) \\\n",
    "#               | (train_log_reg_data['поведение_90_дней'] >= 2)\n",
    "# train_log_reg_data['feature_1'] = feature_1\n",
    "# train_log_reg_data['поведение_90_дней'][train_log_reg_data['поведение_90_дней'] > 6] = -1\n",
    "# train_log_reg_data['поведение_60-89_дней'][train_log_reg_data['поведение_60-89_дней'] > 5] = -1\n",
    "# train_log_reg_data['поведение_30-59_дней'][train_log_reg_data['поведение_30-59_дней'] > 4] = -1\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# col_names = ['доход']  #['поведение_90_дней', 'поведение_30-59_дней', 'поведение_60-89_дней']\n",
    "# features = train_log_reg_data[col_names]\n",
    "# features = StandardScaler().fit_transform(features)\n",
    "# train_log_reg_data[col_names] = features\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# \n",
    "rand_forest_line_grid_param = {'max_depth' : range(2, 7), 'max_features' : range(2, 7),\n",
    "                               'learning_rate' : [1, 0.1, 0.01],\n",
    "                               'loss' : ['exponential', 'deviance'], \n",
    "                                'subsample' : [0.3, 0.7, 0.8]\n",
    "                              }\n",
    "\n",
    "# train_log_reg_data.pop('поведение_30-59_дней')\n",
    "# train_log_reg_data.pop('поведение_60-89_дней')\n",
    "# train_log_reg_data.pop('поведение_90_дней')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_log_reg_data, y, train_size = 0.8, random_state=20)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "assiveAggre_best = GradientBoostingClassifier(learning_rate=0.099,  min_impurity_decrease=0.00001, subsample=0.7, n_estimators=350,\n",
    "min_weight_fraction_leaf = 0.00005,\n",
    "min_impurity_split = 0.00004,\n",
    "max_depth=4,\n",
    "max_features=4,\n",
    "min_samples_leaf= 160, #159\n",
    "min_samples_split= 760, #760\n",
    "random_state = 20)\n",
    "assiveAggre_best1 = GradientBoostingClassifier(n_estimators=175, max_depth=5, max_features='auto', random_state=0, loss='exponential', subsample=0.75, learning_rate=0.1, criterion='mse')\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "knn = RidgeClassifier()\n",
    "\n",
    "#grid_boost = GridSearchCV(estimator=assiveAggre_best, param_grid=rand_forest_line_grid_param, cv=strCV, scoring='roc_auc', verbose=1)\n",
    "\n",
    "degrees = [1, 4, 15]\n",
    "#rfecv_boost = RFECV(estimator=assiveAggre_best, cv=StratifiedKFold(n_splits=4, random_state=20), step=2, scoring='roc_auc', verbose=1)\n",
    "#polynomial_features = PolynomialFeatures(degree=2, interaction_only=True,\n",
    "#                                             include_bias=False)\n",
    "#pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "#                        (\"rfecv_boost\", rfecv_boost)])\n",
    "#train_poly = train_log_reg_data.copy()\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dec_tree = DecisionTreeClassifier(max_depth=9, max_features='auto', criterion='entropy', random_state=5)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=16)\n",
    "rf1 = RandomForestClassifier(n_estimators=125, max_depth=11, max_features=2, random_state=4)\n",
    "rf2 = RandomForestClassifier(n_estimators=100, max_depth=9, max_features=7, random_state=6)\n",
    "rf3 = RandomForestClassifier(n_estimators=100, criterion='entropy', max_depth=10, random_state=0)\n",
    "\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('boost', assiveAggre_best), ('rf1', rf1), ('rf2', rf2), ('rf3', rf3), ('rfecv', rfecv), ('knn', knn)],\n",
    "                        voting='soft', weights=[6, 2, 2, 2, 2, 2])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#pipeline.fit(X_train, y_train)\n",
    "#rfecv_boost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 21 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 21 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 21 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 21 features.\n"
     ]
    }
   ],
   "source": [
    "#assiveAggre_best1.fit(X_train, y_train)\n",
    "# assiveAggre_best1 = assiveAggre_best1.fit(X_train, y_train)\n",
    "\n",
    "# model_rand_forest_new = model_rand_forest_new.fit(X_train, y_train) \n",
    "# model_rand_forest = model_rand_forest.fit(X_train, y_train)\n",
    "#assiveAggre_best.fit(X_train, y_train)\n",
    "eclf = eclf.fit(train_log_reg_data, y)\n",
    "\n",
    "#grid_boost.fit(train, y)\n",
    "#models = [assiveAggre_best, assiveAggre_best1]\n",
    "#stacking1 = DjStacking(models, knn)\n",
    "#stacking1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc=0.8948\n"
     ]
    }
   ],
   "source": [
    "rcParams['figure.figsize'] = 8, 5\n",
    "auc9 = roc_auc_score(y_test, eclf.predict_proba(X_test)[:, 1])\n",
    "print(\"auc=%.4f\" % auc9)\n",
    "#auc=0.8719 - on 80% train\n",
    "#auc=0.8618 - on 20% train\n",
    "#auc=0.8935 - on full train\n",
    "\n",
    "#auc=0.8838 - on full train log reg\n",
    "#auc=0.8701 - on 80% train \n",
    "\n",
    "#auc=0.8989 - on full train with knn log reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rand_forest_prediction = eclf.predict_proba(test_log_reg_data)[:, 1]\n",
    "pd.DataFrame({'id' : np.arange(37500), 'a' : model_rand_forest_prediction}).to_csv('/home/paniquex/PycharmProjects/IML_homeworks/credit_scoring/solution_voting_classifier__weights_3rf_boost_logreg_knn_from_sklearn_with_gridsearch_anomaly_fix.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(probability=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-364-c5658c92c5b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-362-ae8a52dd7dcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#plt.ylabel(\"True Positive Rate (recall)\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#fpr9, tpr9, _= roc_curve(y, model_rand_forest_new.predict_proba(train_log_reg_data)[:, 1] )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mauc9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#plt.plot(fpr9, tpr9, label=(\"auc=%.4f\" % auc9), linewidth=2,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#color='#990000')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \"\"\"\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_check_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             raise AttributeError(\"predict_proba is not available when \"\n\u001b[0m\u001b[1;32m    558\u001b[0m                                  \" probability=False\")\n\u001b[1;32m    559\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'c_svc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nu_svc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "rcParams['figure.figsize'] = 8, 5\n",
    "#plt.figure(figsize=(6,5))\n",
    "#plt.xlabel(\"False Positive Rate\")\n",
    "#plt.ylabel(\"True Positive Rate (recall)\")\n",
    "#fpr9, tpr9, _= roc_curve(y, model_rand_forest_new.predict_proba(train_log_reg_data)[:, 1] )\n",
    "auc9 = roc_auc_score(y_test, svc.predict_proba(X_test)[:, 1])\n",
    "#plt.plot(fpr9, tpr9, label=(\"auc=%.4f\" % auc9), linewidth=2,\n",
    "#color='#990000')\n",
    "\n",
    "#plt.legend(loc=\"best\")\n",
    "print(\"auc=%.4f\" % auc9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest_line_grid_param_new = {'max_depth' : [9], 'max_features' : [3], \n",
    "                               'criterion' : ['entropy'], \n",
    "                              'min_samples_split': [35, 40, 100],\n",
    "                              'min_samples_leaf' : [10],\n",
    "                              'min_impurity_decrease' : [0, 0.01, 0.5, 1],\n",
    "                              'min_weight_fraction_leaf' : [0., 0.000001, 0.00001, 0.5],\n",
    "                              'n_estimators' : [50]}\n",
    "                                            \n",
    "model_rand_forest_line_grid_new = GridSearchCV(estimator=model_rand_forest_line, scoring='roc_auc', param_grid=rand_forest_line_grid_param_new, cv=strCV, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 48 candidates, totalling 192 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-58cfc17a1eda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_rand_forest_line_grid_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "model_rand_forest_line_grid_new.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e0aaf42d47e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_rand_forest_line_grid_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m {'criterion': 'entropy',\n\u001b[1;32m      3\u001b[0m  \u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m  \u001b[0;34m'max_features'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m  \u001b[0;34m'min_impurity_decrease'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "model_rand_forest_line_grid_new.best_params_\n",
    "{'criterion': 'entropy',\n",
    " 'max_depth': 9,\n",
    " 'max_features': 3,\n",
    " 'min_impurity_decrease': 0,\n",
    " 'min_samples_leaf': 20,\n",
    " 'min_samples_split': 30,\n",
    " 'min_weight_fraction_leaf': 0.0,\n",
    " 'n_estimators': 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9c35b1967a13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"False Positive Rate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"True Positive Rate (recall)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfpr9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_rand_forest_line_grid_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mauc9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_rand_forest_line_grid_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m plt.plot(fpr9, tpr9, label=(\"auc=%.3f\" % auc9), linewidth=2,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \"\"\"\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict_proba'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_check_is_fitted\u001b[0;34m(self, method_name)\u001b[0m\n\u001b[1;32m    448\u001b[0m                                  % (type(self).__name__, method_name))\n\u001b[1;32m    449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'best_estimator_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_estimator_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ],
     "output_type": "error"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcParams['figure.figsize'] = 8, 5\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate (recall)\")\n",
    "fpr9, tpr9, _= roc_curve(y_test, model_rand_forest_line_grid_new.predict_proba(X_test)[:, 1] )\n",
    "auc9 = roc_auc_score(y_test, model_rand_forest_line_grid_new.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr9, tpr9, label=(\"auc=%.3f\" % auc9), linewidth=2,\n",
    "color='#990000')\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rand_forest_new = RandomForestClassifier(n_estimators=100, criterion= 'entropy',\n",
    " max_depth= 10,\n",
    " max_features= 10,\n",
    " min_samples_leaf= 20,\n",
    " min_samples_split= 30,\n",
    " oob_score= False,\n",
    " random_state = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 8, 5\n",
    "#plt.figure(figsize=(6,5))\n",
    "#plt.xlabel(\"False Positive Rate\")\n",
    "#plt.ylabel(\"True Positive Rate (recall)\")\n",
    "#fpr9, tpr9, _= roc_curve(y, model_rand_forest_new.predict_proba(train_log_reg_data)[:, 1] )\n",
    "auc9 = roc_auc_score(y_test, model_rand_forest_new.predict_proba(X_test)[:, 1])\n",
    "#plt.plot(fpr9, tpr9, label=(\"auc=%.4f\" % auc9), linewidth=2,\n",
    "#color='#990000')\n",
    "#plt.legend(loc=\"best\")\n",
    "print(\"auc=%.4f\" % auc9)\n",
    "#auc=0.8742"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных для использования логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>линии</th>\n",
       "      <th>возраст</th>\n",
       "      <th>поведение_30-59_дней</th>\n",
       "      <th>Debt_Ratio</th>\n",
       "      <th>доход</th>\n",
       "      <th>число_кредитов</th>\n",
       "      <th>поведение_90_дней</th>\n",
       "      <th>недвижимость</th>\n",
       "      <th>поведение_60-89_дней</th>\n",
       "      <th>семья</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>112500.000000</td>\n",
       "      <td>112500.000000</td>\n",
       "      <td>112500.000000</td>\n",
       "      <td>112500.000000</td>\n",
       "      <td>1.125000e+05</td>\n",
       "      <td>112500.000000</td>\n",
       "      <td>112500.000000</td>\n",
       "      <td>112500.000000</td>\n",
       "      <td>112500.000000</td>\n",
       "      <td>112500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.057904</td>\n",
       "      <td>52.292702</td>\n",
       "      <td>0.425538</td>\n",
       "      <td>350.965444</td>\n",
       "      <td>6.662380e+03</td>\n",
       "      <td>8.464267</td>\n",
       "      <td>0.271627</td>\n",
       "      <td>1.019680</td>\n",
       "      <td>0.245333</td>\n",
       "      <td>0.762071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.959993</td>\n",
       "      <td>14.765029</td>\n",
       "      <td>4.246085</td>\n",
       "      <td>1864.557746</td>\n",
       "      <td>1.379656e+04</td>\n",
       "      <td>5.149137</td>\n",
       "      <td>4.223498</td>\n",
       "      <td>1.130324</td>\n",
       "      <td>4.208686</td>\n",
       "      <td>1.099412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.029840</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175069</td>\n",
       "      <td>3.900000e+03</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.154015</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366336</td>\n",
       "      <td>6.600000e+03</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.559389</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.863569</td>\n",
       "      <td>7.400000e+03</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50708.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>326442.000000</td>\n",
       "      <td>3.008750e+06</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>линии</th>\n",
       "      <th>возраст</th>\n",
       "      <th>поведение_30-59_дней</th>\n",
       "      <th>Debt_Ratio</th>\n",
       "      <th>доход</th>\n",
       "      <th>число_кредитов</th>\n",
       "      <th>поведение_90_дней</th>\n",
       "      <th>недвижимость</th>\n",
       "      <th>поведение_60-89_дней</th>\n",
       "      <th>семья</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>112500.000000</td>\n",
       "      <td>112500.000000</td>\n",
       "      <td>112500.000000</td>\n",
       "      <td>112500.000000</td>\n",
       "      <td>1.125000e+05</td>\n",
       "      <td>112500.000000</td>\n",
       "      <td>112500.000000</td>\n",
       "      <td>112500.000000</td>\n",
       "      <td>112500.000000</td>\n",
       "      <td>112500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.057904</td>\n",
       "      <td>52.292702</td>\n",
       "      <td>0.425538</td>\n",
       "      <td>350.965444</td>\n",
       "      <td>6.662380e+03</td>\n",
       "      <td>8.464267</td>\n",
       "      <td>0.271627</td>\n",
       "      <td>1.019680</td>\n",
       "      <td>0.245333</td>\n",
       "      <td>0.762071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.959993</td>\n",
       "      <td>14.765029</td>\n",
       "      <td>4.246085</td>\n",
       "      <td>1864.557746</td>\n",
       "      <td>1.379656e+04</td>\n",
       "      <td>5.149137</td>\n",
       "      <td>4.223498</td>\n",
       "      <td>1.130324</td>\n",
       "      <td>4.208686</td>\n",
       "      <td>1.099412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.029840</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175069</td>\n",
       "      <td>3.900000e+03</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.154015</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366336</td>\n",
       "      <td>6.600000e+03</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.559389</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.863569</td>\n",
       "      <td>7.400000e+03</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50708.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>326442.000000</td>\n",
       "      <td>3.008750e+06</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_log = train.copy()\n",
    "test_log = test.copy()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#col_names = ['линии', 'доход', 'Debt_Ratio']\n",
    "#features = train_log[col_names]\n",
    "#scaler = StandardScaler(with_mean = False, with_std = True).fit(features.values)\n",
    "#features = scaler.transform(features.values)\n",
    "#train_log[col_names] = features\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(train_log, y, train_size = 0.2)\n",
    "train_log.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-02e1d5a03d99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlog_reg_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrfecv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFECV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_reg_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrfecv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    434\u001b[0m         scores = parallel(\n\u001b[1;32m    435\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             for train, test in cv.split(X, y))\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "train_with_out_60_30 = train_log.copy()\n",
    "train_with_out_60_30.pop('поведение_30-59_дней')\n",
    "train_with_out_60_30.pop('поведение_60-89_дней')\n",
    "log_reg_first = LogisticRegression()\n",
    "rfecv = RFECV(estimator=log_reg_first, cv=5, scoring='accuracy', n_jobs=-1, step=1)\n",
    "rfecv.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 18 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 18 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 18 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 18 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFECV(cv=StratifiedKFold(n_splits=4, random_state=20, shuffle=False),\n   estimator=LogisticRegression(C=1, class_weight='balanced', dual=False,\n          fit_intercept=True, intercept_scaling=1, max_iter=300,\n          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n          solver='liblinear', tol=1e-06, verbose=0, warm_start=False),\n   n_jobs=1, scoring='roc_auc', step=95, verbose=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(max_iter=200, penalty='l2', C=0.01, random_state=20, class_weight=  'balanced', tol=0.00004, solver = 'sag')\n",
    "train_with_new_features =  train.copy()\n",
    "train_log_reg_data = train_with_new_features.copy()\n",
    "##большие значения у линий - выбросы, уберем их\n",
    "\n",
    "\n",
    "\n",
    "train_log_reg_data['линии'][(train_log_reg_data['линии'] >= 10)] = 0.3\n",
    "train_log_reg_data['доход'][train_log_reg_data['доход'] > train_log_reg_data['доход'].quantile(q=0.85)] = train_log_reg_data['доход'].quantile(q=0.4)\n",
    "train_log_reg_data['Debt_Ratio'][train_log_reg_data['Debt_Ratio'] > train_log_reg_data['Debt_Ratio'].quantile(q=0.8)] = train_log_reg_data['Debt_Ratio'].quantile(q=0.4)\n",
    "\n",
    "feature_1 = (train_log_reg_data['поведение_30-59_дней'] >= 1) #| (train_log_reg_data['поведение_60-89_дней'] >= 1) \\\n",
    "            # | (train_log_reg_data['поведение_90_дней'] >= 1)\n",
    "train_log_reg_data['feature_1'] = feature_1\n",
    "train_log_reg_data['поведение_90_дней'][train_log_reg_data['поведение_90_дней'] > 35] = 1\n",
    "train_log_reg_data['поведение_60-89_дней'][train_log_reg_data['поведение_60-89_дней'] > 35] = 1\n",
    "train_log_reg_data['поведение_30-59_дней'][train_log_reg_data['поведение_30-59_дней'] > 35] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feature_2 = (train_log_reg_data['недвижимость'] >= 1) \n",
    "train_log_reg_data['feature_2'] = feature_2\n",
    "\n",
    "feature_3 = (train_log_reg_data['число_кредитов'] >= 15)\n",
    "train_log_reg_data['feature_3'] = feature_3\n",
    "\n",
    "feature_4 = (train_log_reg_data['доход'] <= train_log_reg_data['доход'].quantile(q=0.35))\n",
    "train_log_reg_data['feature_4'] = feature_4\n",
    "\n",
    "feature_5 = (train_log_reg_data['Debt_Ratio'] <= train_log_reg_data['Debt_Ratio'].quantile(q=0.5))\n",
    "train_log_reg_data['feature_5'] = feature_5\n",
    "\n",
    "feature_6 = (train_log_reg_data['линии'] <= train_log_reg_data['линии'].quantile(q=0.05))\n",
    "train_log_reg_data['feature_6'] = feature_6\n",
    "\n",
    "feature_7 = (train_log_reg_data['поведение_60-89_дней'] >= 1)\n",
    "train_log_reg_data['feature_7'] = feature_7\n",
    "\n",
    "feature_8 = (train_log_reg_data['поведение_90_дней'] >= 1)\n",
    "train_log_reg_data['feature_8'] = feature_8\n",
    "\n",
    "feature_9 = (train_log_reg_data['возраст'] >= train_log_reg_data['возраст'].quantile(q=0.6))\n",
    "train_log_reg_data['feature_9'] = feature_9\n",
    "\n",
    "feature_10 = (3*train_log_reg_data['поведение_60-89_дней'] + 5 * train_log_reg_data['поведение_30-59_дней']) > train_log_reg_data['поведение_90_дней']\n",
    "train_log_reg_data['feature_10'] = feature_10\n",
    "\n",
    "feature_11 = np.log2(train_log_reg_data['линии']+ 0.00001)\n",
    "train_log_reg_data['feature_11'] = feature_11\n",
    "\n",
    "\n",
    "\n",
    "# train_log_reg_data.pop('поведение_30-59_дней')\n",
    "# train_log_reg_data.pop('поведение_60-89_дней')\n",
    "# train_log_reg_data.pop('поведение_90_дней')\n",
    "# train_log_reg_data['feature_1'][train_log_reg_data['feature_1'] == True] = 1\n",
    "# train_log_reg_data['feature_1'][train_log_reg_data['feature_1'] == False] = 0\n",
    "# train_log_reg_data['feature_2'][train_log_reg_data['feature_2'] == True] = 1\n",
    "# train_log_reg_data['feature_2'][train_log_reg_data['feature_2'] == False] = 0\n",
    "# train_log_reg_data['feature_3'][train_log_reg_data['feature_3'] == True] = 1\n",
    "# train_log_reg_data['feature_3'][train_log_reg_data['feature_3'] == False] = 0\n",
    "# train_log_reg_data['feature_4'][train_log_reg_data['feature_4'] == True] = 1\n",
    "# train_log_reg_data['feature_4'][train_log_reg_data['feature_4'] == False] = 0\n",
    "# train_log_reg_data['feature_5'][train_log_reg_data['feature_5'] == True] = 1\n",
    "# train_log_reg_data['feature_5'][train_log_reg_data['feature_5'] == False] = 0\n",
    "# \n",
    "# train_log_reg_data['feature_1'] = train_log_reg_data['feature_1'].astype(bool)\n",
    "# train_log_reg_data['feature_2'] = train_log_reg_data['feature_2'].astype(bool)\n",
    "# train_log_reg_data['feature_3'] = train_log_reg_data['feature_3'].astype(bool)\n",
    "train_log_reg_data['семья'] = train_log_reg_data['семья'].astype(int)\n",
    "\n",
    "\n",
    "col_names = ['линии', 'доход', 'Debt_Ratio']\n",
    "features = train_log_reg_data[col_names]\n",
    "features = StandardScaler().fit_transform(features)\n",
    "train_log_reg_data[col_names] = features\n",
    "\n",
    "train_with_new_feature1 = train_log_reg_data.copy()\n",
    "new_feature = np.log(train['линии']+0.000001) + train['возраст'] + \\\n",
    "    train['поведение_30-59_дней'] + train['поведение_60-89_дней'] + \\\n",
    "    train['поведение_90_дней'] + train['доход'] + train['Debt_Ratio'] + \\\n",
    "    train['семья']\n",
    "train_with_new_feature1['feature_new'] = new_feature\n",
    "# train_with_new_feature1.pop('линии')\n",
    "# train_with_new_feature1.pop('доход')\n",
    "# train_with_new_feature1.pop('Debt_Ratio')\n",
    "# train_with_new_feature1.pop('поведение_30-59_дней')\n",
    "# train_with_new_feature1.pop('поведение_60-89_дней')\n",
    "# train_with_new_feature1.pop('поведение_90_дней')\n",
    "# train_with_new_feature1.pop('семья')\n",
    "# train_with_new_feature1.pop('возраст')\n",
    "# train_with_new_feature1.pop('число_кредитов')\n",
    "# train_with_new_feature1.pop('недвижимость')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_with_new_feature1, y, train_size = 0.8, random_state=20)\n",
    "# grid_rfecv_params = {'tol' : [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001],\n",
    "#                      'C' : [1, 0.5, 0.1, 0.01, 0.001, 0.0001],\n",
    "#                      'fit_intercept' : [True, False],\n",
    "#                       'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "#                       'max_iter' : [100, 200, 300, 500]\n",
    "#                        }\n",
    "log_reg_with_grid = LogisticRegression(penalty='l2', C=1, fit_intercept= True,  max_iter= 300, solver='liblinear', tol=0.000001, class_weight='balanced' )\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "passiveAggre = GradientBoostingClassifier(learning_rate=0.1)\n",
    "# passiveAggre.fit(X_train, y_train)\n",
    "#grid_rfecv = GridSearchCV(estimator=logreg, param_grid=grid_rfecv_params, n_jobs=-1, scoring='roc_auc', cv=StratifiedKFold(n_splits=5), verbose=1)\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "rfecv = RFECV(estimator=log_reg_with_grid, cv=StratifiedKFold(n_splits=4, random_state=20), step=95, scoring='roc_auc', verbose=1)\n",
    "#train_log_reg_data.info()\n",
    "rfecv.fit(X_train, y_train)\n",
    "#svc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.ranking_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc=0.8670\n"
     ]
    }
   ],
   "source": [
    "#rcParams['figure.figsize'] = 8, 5\n",
    "#plt.figure(figsize=(6,5))\n",
    "#plt.xlabel(\"False Positive Rate\")\n",
    "#plt.ylabel(\"True Positive Rate (recall)\")\n",
    "#fpr9, tpr9, _= roc_curve(y_test, knn.predict_proba(X_test)[:, 1] )\n",
    "auc9 = roc_auc_score(y_test, rfecv.predict_proba(X_test)[:, 1])\n",
    "#plt.plot(fpr9, tpr9, label=(\"auc=%.4f\" % auc9), linewidth=2,\n",
    "#color='#990000')\n",
    "#plt.legend(loc=\"best\")\n",
    "print(\"auc=%.4f\" % auc9)\n",
    "#auc=0.8675\n",
    "\n",
    "#auc=0.8687\n",
    "\n",
    "#auc=0.8669\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f20edce46a0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcParams['figure.figsize'] = 8, 5\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate (recall)\")\n",
    "fpr9, tpr9, _= roc_curve(y_test, rfecv.predict_proba(X_test)[:, 1] )\n",
    "auc9 = roc_auc_score(y_test, rfecv.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr9, tpr9, label=(\"auc=%.4f\" % auc9), linewidth=2,\n",
    "color='#990000')\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 987 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 892 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 797 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 702 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 607 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 512 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 417 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 322 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 227 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 132 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 37 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 987 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 892 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 797 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 702 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 607 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 512 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 417 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 322 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 227 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 132 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 37 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 987 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 892 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 797 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 702 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 607 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 512 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 417 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 322 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 227 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 132 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 37 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 987 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 892 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 797 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 702 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 607 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 512 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 417 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 322 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 227 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 132 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 37 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "degrees = [1, 4, 15]\n",
    "polynomial_features = PolynomialFeatures(degree=3, interaction_only=True,\n",
    "                                             include_bias=False)\n",
    "pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"rfecv\", rfecv)])\n",
    "train_poly = train_with_new_feature1.copy()\n",
    "#polynomial_features.fit(train_poly, y)\n",
    "#train_poly = polynomial_features.transform(train_poly)\n",
    "pipeline.fit(train_poly, y)\n",
    "\n",
    "print('2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 5, 7, 1, 1, 5, 1, 4, 1, 1, 7, 1, 1, 2, 1, 2, 1, 1, 6, 1,\n       1, 1, 1, 1, 1, 1, 1, 7, 1, 1, 4, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 4, 5, 1, 1, 3, 4, 3, 1, 1, 1, 6, 3, 4, 4, 1, 2,\n       6, 1, 6, 1, 7, 3, 6, 5, 8, 6, 6, 2, 5, 2, 4, 1, 6, 1, 1, 1, 4, 6,\n       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 4, 1, 1, 3, 1, 6, 4, 4, 1, 3, 5,\n       7, 5, 1, 5, 1, 2, 4, 7, 4, 5, 8, 4, 5, 5, 4, 3, 1, 1, 5, 7, 1, 5,\n       6, 1, 2, 1, 2, 7, 1, 1, 6, 1, 2, 4, 7, 4, 4, 5, 1, 1, 7, 5, 5, 5,\n       4, 2, 7, 7, 7, 6, 2, 5, 6, 1, 2, 5, 4, 2, 5, 2, 1, 1, 1, 1, 1, 1,\n       3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 4, 7, 1, 1, 1, 1, 3, 3, 1, 1, 6, 4,\n       1, 7, 1, 3, 5, 1, 6, 1, 5, 7, 7, 4, 8, 8, 5, 6, 8, 5, 1, 1, 5, 1,\n       1, 1, 5, 7, 1, 1, 4, 1, 3, 2, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 3, 1,\n       3, 3, 1, 4, 7, 4, 1, 6, 1, 2, 4, 3, 1, 1, 8, 5, 6, 4, 1, 3, 1, 3,\n       4, 7, 1, 5, 6, 1, 4, 3, 3, 7, 1, 3, 6, 1, 8, 1, 7, 4, 4, 6, 1, 2,\n       8, 5, 5, 8, 1, 2, 7, 8, 7, 7, 2, 5, 6, 1, 2, 7, 3, 2, 6, 2, 2, 1,\n       1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 4, 1, 1, 2, 1, 1, 1, 1, 1,\n       7, 1, 2, 1, 1, 4, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 4, 1, 1, 2,\n       2, 2, 1, 1, 1, 2, 2, 1, 5, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 7, 1, 3,\n       1, 1, 1, 1, 1, 1, 2, 4, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1,\n       1, 1, 4, 1, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 7, 1, 1, 1, 1, 8, 1,\n       1, 1, 3, 1, 1, 8, 1, 8, 3, 7, 1, 4, 1, 1, 5, 5, 5, 7, 5, 6, 6, 5,\n       2, 1, 3, 8, 3, 3, 1, 8, 6, 4, 4, 7, 1, 3, 1, 1, 1, 1, 1, 1, 6, 3,\n       3, 1, 1, 4, 5, 4, 4, 3, 5, 7, 4, 3, 8, 3, 3, 5, 1, 4, 4, 8, 5, 6,\n       7, 4, 4, 3, 3, 8, 6, 3, 5, 8, 3, 3, 1, 1, 6, 3, 4, 5, 1, 7, 1, 6,\n       3, 4, 4, 1, 2, 7, 5, 6, 8, 1, 2, 6, 7, 8, 6, 4, 5, 8, 3, 2, 8, 4,\n       4, 4, 4, 1, 1, 5, 1, 5, 1, 7, 6, 6, 5, 6, 7, 8, 3, 1, 1, 4, 1, 1,\n       1, 1, 1, 5, 1, 1, 4, 7, 6, 1, 7, 7, 8, 6, 6, 5, 6, 2, 5, 1, 5, 1,\n       5, 5, 8, 1, 5, 3, 8, 6, 8, 8, 7, 6, 7, 7, 2, 7, 7, 6, 8, 6, 8, 7,\n       6, 5, 8, 6, 7, 7, 6, 2, 6, 7, 8, 5, 7, 5, 8, 8, 7, 8, 2, 6, 8, 7,\n       2, 8, 7, 2, 8, 2, 2, 3, 6, 1, 1, 1, 1, 1, 1, 3, 4, 1, 4, 5, 4, 3,\n       3, 7, 6, 5, 1, 5, 1, 3, 8, 1, 7, 6, 8, 8, 7, 5, 5, 3, 1, 1, 8, 7,\n       1, 5, 5, 1, 2, 1, 1, 7, 1, 4, 6, 1, 3, 7, 6, 4, 4, 8, 1, 4, 8, 7,\n       8, 8, 5, 2, 7, 7, 7, 6, 2, 5, 6, 1, 2, 8, 3, 2, 5, 2, 3, 1, 1, 3,\n       1, 3, 7, 4, 1, 3, 1, 3, 3, 1, 1, 1, 1, 3, 3, 3, 1, 4, 1, 1, 1, 5,\n       1, 3, 1, 1, 3, 1, 5, 1, 1, 3, 1, 2, 4, 1, 6, 1, 2, 5, 1, 3, 3, 3,\n       3, 1, 4, 3, 5, 5, 8, 6, 3, 4, 6, 1, 3, 3, 1, 2, 7, 3, 3, 6, 8, 6,\n       4, 8, 6, 4, 6, 6, 7, 6, 5, 6, 8, 4, 4, 8, 4, 3, 4, 6, 8, 6, 1, 6,\n       3, 2, 6, 7, 5, 3, 7, 1, 2, 8, 7, 5, 8, 6, 2, 8, 7, 8, 7, 2, 5, 8,\n       5, 3, 5, 1, 2, 7, 2, 2, 4, 5, 4, 7, 4, 6, 6, 4, 3, 1, 7, 6, 4, 8,\n       7, 1, 3, 4, 8, 5, 6, 6, 4, 3, 8, 4, 5, 5, 4, 3, 7, 8, 8, 8, 2, 7,\n       6, 4, 3, 6, 6, 2, 6, 3, 3, 4, 4, 7, 1, 6, 7, 1, 2, 5, 7, 1, 5, 7,\n       1, 2, 8, 5, 8, 8, 5, 2, 7, 8, 8, 7, 2, 5, 6, 1, 2, 8, 5, 2, 6, 2,\n       3, 1, 7, 5, 5, 6, 1, 4, 6, 5, 7, 7, 1, 3, 8, 8, 8, 7, 3, 6, 8, 1,\n       2, 8, 4, 2, 6, 4, 2, 7, 6, 6, 8, 4, 2, 7, 8, 8, 7, 2, 6, 7, 4, 1,\n       8, 4, 3, 5, 3, 1, 8, 8, 8, 8, 2, 8, 8, 5, 2, 8, 6, 3, 7, 6, 2, 8,\n       8, 7, 2, 8, 8, 2, 8, 3, 2, 8, 5, 2, 6, 2, 1, 8, 2, 2, 2])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.ranking_\n",
    "# array([1, 1, 1, 5, 7, 1, 1, 5, 1, 4, 1, 1, 7, 1, 1, 2, 1, 2, 1, 1, 6, 1,\n",
    "#        1, 1, 1, 1, 1, 1, 1, 7, 1, 1, 4, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "#        1, 1, 1, 1, 1, 1, 4, 5, 1, 1, 3, 4, 3, 1, 1, 1, 6, 3, 4, 4, 1, 2,\n",
    "#        6, 1, 6, 1, 7, 3, 6, 5, 8, 6, 6, 2, 5, 2, 4, 1, 6, 1, 1, 1, 4, 6,\n",
    "#        1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 4, 1, 1, 3, 1, 6, 4, 4, 1, 3, 5,\n",
    "#        7, 5, 1, 5, 1, 2, 4, 7, 4, 5, 8, 4, 5, 5, 4, 3, 1, 1, 5, 7, 1, 5,\n",
    "#        6, 1, 2, 1, 2, 7, 1, 1, 6, 1, 2, 4, 7, 4, 4, 5, 1, 1, 7, 5, 5, 5,\n",
    "#        4, 2, 7, 7, 7, 6, 2, 5, 6, 1, 2, 5, 4, 2, 5, 2, 1, 1, 1, 1, 1, 1,\n",
    "#        3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 4, 7, 1, 1, 1, 1, 3, 3, 1, 1, 6, 4,\n",
    "#        1, 7, 1, 3, 5, 1, 6, 1, 5, 7, 7, 4, 8, 8, 5, 6, 8, 5, 1, 1, 5, 1,\n",
    "#        1, 1, 5, 7, 1, 1, 4, 1, 3, 2, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 3, 1,\n",
    "#        3, 3, 1, 4, 7, 4, 1, 6, 1, 2, 4, 3, 1, 1, 8, 5, 6, 4, 1, 3, 1, 3,\n",
    "#        4, 7, 1, 5, 6, 1, 4, 3, 3, 7, 1, 3, 6, 1, 8, 1, 7, 4, 4, 6, 1, 2,\n",
    "#        8, 5, 5, 8, 1, 2, 7, 8, 7, 7, 2, 5, 6, 1, 2, 7, 3, 2, 6, 2, 2, 1,\n",
    "#        1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 4, 1, 1, 2, 1, 1, 1, 1, 1,\n",
    "#        7, 1, 2, 1, 1, 4, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 4, 1, 1, 2,\n",
    "#        2, 2, 1, 1, 1, 2, 2, 1, 5, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 7, 1, 3,\n",
    "#        1, 1, 1, 1, 1, 1, 2, 4, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1,\n",
    "#        1, 1, 4, 1, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 7, 1, 1, 1, 1, 8, 1,\n",
    "#        1, 1, 3, 1, 1, 8, 1, 8, 3, 7, 1, 4, 1, 1, 5, 5, 5, 7, 5, 6, 6, 5,\n",
    "#        2, 1, 3, 8, 3, 3, 1, 8, 6, 4, 4, 7, 1, 3, 1, 1, 1, 1, 1, 1, 6, 3,\n",
    "#        3, 1, 1, 4, 5, 4, 4, 3, 5, 7, 4, 3, 8, 3, 3, 5, 1, 4, 4, 8, 5, 6,\n",
    "#        7, 4, 4, 3, 3, 8, 6, 3, 5, 8, 3, 3, 1, 1, 6, 3, 4, 5, 1, 7, 1, 6,\n",
    "#        3, 4, 4, 1, 2, 7, 5, 6, 8, 1, 2, 6, 7, 8, 6, 4, 5, 8, 3, 2, 8, 4,\n",
    "#        4, 4, 4, 1, 1, 5, 1, 5, 1, 7, 6, 6, 5, 6, 7, 8, 3, 1, 1, 4, 1, 1,\n",
    "#        1, 1, 1, 5, 1, 1, 4, 7, 6, 1, 7, 7, 8, 6, 6, 5, 6, 2, 5, 1, 5, 1,\n",
    "#        5, 5, 8, 1, 5, 3, 8, 6, 8, 8, 7, 6, 7, 7, 2, 7, 7, 6, 8, 6, 8, 7,\n",
    "#        6, 5, 8, 6, 7, 7, 6, 2, 6, 7, 8, 5, 7, 5, 8, 8, 7, 8, 2, 6, 8, 7,\n",
    "#        2, 8, 7, 2, 8, 2, 2, 3, 6, 1, 1, 1, 1, 1, 1, 3, 4, 1, 4, 5, 4, 3,\n",
    "#        3, 7, 6, 5, 1, 5, 1, 3, 8, 1, 7, 6, 8, 8, 7, 5, 5, 3, 1, 1, 8, 7,\n",
    "#        1, 5, 5, 1, 2, 1, 1, 7, 1, 4, 6, 1, 3, 7, 6, 4, 4, 8, 1, 4, 8, 7,\n",
    "#        8, 8, 5, 2, 7, 7, 7, 6, 2, 5, 6, 1, 2, 8, 3, 2, 5, 2, 3, 1, 1, 3,\n",
    "#        1, 3, 7, 4, 1, 3, 1, 3, 3, 1, 1, 1, 1, 3, 3, 3, 1, 4, 1, 1, 1, 5,\n",
    "#        1, 3, 1, 1, 3, 1, 5, 1, 1, 3, 1, 2, 4, 1, 6, 1, 2, 5, 1, 3, 3, 3,\n",
    "#        3, 1, 4, 3, 5, 5, 8, 6, 3, 4, 6, 1, 3, 3, 1, 2, 7, 3, 3, 6, 8, 6,\n",
    "#        4, 8, 6, 4, 6, 6, 7, 6, 5, 6, 8, 4, 4, 8, 4, 3, 4, 6, 8, 6, 1, 6,\n",
    "#        3, 2, 6, 7, 5, 3, 7, 1, 2, 8, 7, 5, 8, 6, 2, 8, 7, 8, 7, 2, 5, 8,\n",
    "#        5, 3, 5, 1, 2, 7, 2, 2, 4, 5, 4, 7, 4, 6, 6, 4, 3, 1, 7, 6, 4, 8,\n",
    "#        7, 1, 3, 4, 8, 5, 6, 6, 4, 3, 8, 4, 5, 5, 4, 3, 7, 8, 8, 8, 2, 7,\n",
    "#        6, 4, 3, 6, 6, 2, 6, 3, 3, 4, 4, 7, 1, 6, 7, 1, 2, 5, 7, 1, 5, 7,\n",
    "#        1, 2, 8, 5, 8, 8, 5, 2, 7, 8, 8, 7, 2, 5, 6, 1, 2, 8, 5, 2, 6, 2,\n",
    "#        3, 1, 7, 5, 5, 6, 1, 4, 6, 5, 7, 7, 1, 3, 8, 8, 8, 7, 3, 6, 8, 1,\n",
    "#        2, 8, 4, 2, 6, 4, 2, 7, 6, 6, 8, 4, 2, 7, 8, 8, 7, 2, 6, 7, 4, 1,\n",
    "#        8, 4, 3, 5, 3, 1, 8, 8, 8, 8, 2, 8, 8, 5, 2, 8, 6, 3, 7, 6, 2, 8,\n",
    "#        8, 7, 2, 8, 8, 2, 8, 3, 2, 8, 5, 2, 6, 2, 1, 8, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc=0.8660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcParams['figure.figsize'] = 8, 5\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate (recall)\")\n",
    "#fpr9, tpr9, _= roc_curve(y_train, pipeline.predict_proba(X_train)[:, 1] )\n",
    "auc9 = roc_auc_score(y, pipeline.predict_proba(train_poly)[:, 1])\n",
    "#plt.plot(fpr9, tpr9, label=(\"auc=%.4f\" % auc9), linewidth=2, color='#990000')\n",
    "#plt.legend(loc=\"best\")\n",
    "#auc=0.8660 // degree - 3, 2, interaction = True\n",
    "print(\"auc=%.4f\" % auc9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_with_new_features =  test.copy()\n",
    "test_log_reg_data = test_with_new_features.copy()\n",
    "##большие значения у линий - выбросы, уберем их\n",
    "\n",
    "\n",
    "\n",
    "test_log_reg_data['линии'][(test_log_reg_data['линии'] >= 10)] = 0.3\n",
    "test_log_reg_data['доход'][test_log_reg_data['доход'] > test_log_reg_data['доход'].quantile(q=0.85)] = test_log_reg_data['доход'].quantile(q=0.4)\n",
    "test_log_reg_data['Debt_Ratio'][test_log_reg_data['Debt_Ratio'] > test_log_reg_data['Debt_Ratio'].quantile(q=0.8)] = test_log_reg_data['Debt_Ratio'].quantile(q=0.4)\n",
    "\n",
    "feature_1 = (test_log_reg_data['поведение_30-59_дней'] >= 1) #| (test_log_reg_data['поведение_60-89_дней'] >= 1) \\\n",
    "            # | (test_log_reg_data['поведение_90_дней'] >= 1)\n",
    "test_log_reg_data['feature_1'] = feature_1\n",
    "test_log_reg_data['поведение_90_дней'][test_log_reg_data['поведение_90_дней'] > 35] = 1\n",
    "test_log_reg_data['поведение_60-89_дней'][test_log_reg_data['поведение_60-89_дней'] > 35] = 1\n",
    "test_log_reg_data['поведение_30-59_дней'][test_log_reg_data['поведение_30-59_дней'] > 35] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feature_2 = (test_log_reg_data['недвижимость'] >= 1) \n",
    "test_log_reg_data['feature_2'] = feature_2\n",
    "\n",
    "# feature_3 = (test_log_reg_data['число_кредитов'] >= 15)\n",
    "# test_log_reg_data['feature_3'] = feature_3\n",
    "\n",
    "# feature_4 = (test_log_reg_data['доход'] <= test_log_reg_data['доход'].quantile(q=0.35))\n",
    "# test_log_reg_data['feature_4'] = feature_4\n",
    "\n",
    "# feature_5 = (test_log_reg_data['Debt_Ratio'] <= test_log_reg_data['Debt_Ratio'].quantile(q=0.5))\n",
    "# test_log_reg_data['feature_5'] = feature_5\n",
    "\n",
    "feature_6 = (test_log_reg_data['линии'] <= test_log_reg_data['линии'].quantile(q=0.05))\n",
    "test_log_reg_data['feature_6'] = feature_6\n",
    "\n",
    "feature_7 = (test_log_reg_data['поведение_60-89_дней'] >= 1)\n",
    "test_log_reg_data['feature_7'] = feature_7\n",
    "\n",
    "feature_8 = (test_log_reg_data['поведение_90_дней'] >= 1)\n",
    "test_log_reg_data['feature_8'] = feature_8\n",
    "\n",
    "feature_9 = (test_log_reg_data['возраст'] >= test_log_reg_data['возраст'].quantile(q=0.6))\n",
    "test_log_reg_data['feature_9'] = feature_9\n",
    "\n",
    "feature_10 = (3*test_log_reg_data['поведение_60-89_дней'] + 5 * test_log_reg_data['поведение_30-59_дней']) > test_log_reg_data['поведение_90_дней']\n",
    "test_log_reg_data['feature_10'] = feature_10\n",
    "\n",
    "# feature_11 = np.log2(test_log_reg_data['линии']+ 0.00001)\n",
    "# test_log_reg_data['feature_11'] = feature_11\n",
    "\n",
    "\n",
    "\n",
    "# test_log_reg_data.pop('поведение_30-59_дней')\n",
    "# test_log_reg_data.pop('поведение_60-89_дней')\n",
    "# test_log_reg_data.pop('поведение_90_дней')\n",
    "# test_log_reg_data['feature_1'][test_log_reg_data['feature_1'] == True] = 1\n",
    "# test_log_reg_data['feature_1'][test_log_reg_data['feature_1'] == False] = 0\n",
    "# test_log_reg_data['feature_2'][test_log_reg_data['feature_2'] == True] = 1\n",
    "# test_log_reg_data['feature_2'][test_log_reg_data['feature_2'] == False] = 0\n",
    "# test_log_reg_data['feature_3'][test_log_reg_data['feature_3'] == True] = 1\n",
    "# test_log_reg_data['feature_3'][test_log_reg_data['feature_3'] == False] = 0\n",
    "# test_log_reg_data['feature_4'][test_log_reg_data['feature_4'] == True] = 1\n",
    "# test_log_reg_data['feature_4'][test_log_reg_data['feature_4'] == False] = 0\n",
    "# test_log_reg_data['feature_5'][test_log_reg_data['feature_5'] == True] = 1\n",
    "# test_log_reg_data['feature_5'][test_log_reg_data['feature_5'] == False] = 0\n",
    "# \n",
    "# test_log_reg_data['feature_1'] = test_log_reg_data['feature_1'].astype(bool)\n",
    "# test_log_reg_data['feature_2'] = test_log_reg_data['feature_2'].astype(bool)\n",
    "# test_log_reg_data['feature_3'] = test_log_reg_data['feature_3'].astype(bool)\n",
    "test_log_reg_data['семья'] = test_log_reg_data['семья'].astype(int)\n",
    "\n",
    "\n",
    "col_names = ['линии', 'доход', 'Debt_Ratio']\n",
    "features = test_log_reg_data[col_names]\n",
    "features = StandardScaler().fit_transform(features)\n",
    "test_log_reg_data[col_names] = features\n",
    "\n",
    "test_with_new_feature1 = test_log_reg_data.copy()\n",
    "new_feature = np.log(test['линии']+0.000001) + test['возраст'] + \\\n",
    "    test['поведение_30-59_дней'] + test['поведение_60-89_дней'] + \\\n",
    "    test['поведение_90_дней'] + test['доход'] + test['Debt_Ratio'] + \\\n",
    "    test['семья']\n",
    "test_with_new_feature1['feature_new'] = new_feature\n",
    "# test_with_new_feature1.pop('линии')\n",
    "# test_with_new_feature1.pop('доход')\n",
    "# test_with_new_feature1.pop('Debt_Ratio')\n",
    "# test_with_new_feature1.pop('поведение_30-59_дней')\n",
    "# test_with_new_feature1.pop('поведение_60-89_дней')\n",
    "# test_with_new_feature1.pop('поведение_90_дней')\n",
    "# test_with_new_feature1.pop('семья')\n",
    "# test_with_new_feature1.pop('возраст')\n",
    "# test_with_new_feature1.pop('число_кредитов')\n",
    "# test_with_new_feature1.pop('недвижимость')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logreg_pipeline_prediction = pipeline.predict_proba(test_with_new_feature1)[:, 1]\n",
    "pd.DataFrame({'id' : np.arange(37500), 'a' : model_logreg_pipeline_prediction}).to_csv('/home/paniquex/PycharmProjects/IML_homeworks/credit_scoring/solution_logistic_reg_pipeline_polynomial_3degrees_with_new_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 37500 entries, 0 to 37499\nData columns (total 18 columns):\nлинии                   37500 non-null float64\nвозраст                 37500 non-null int64\nповедение_30-59_дней    37500 non-null int64\nDebt_Ratio              37500 non-null float64\nдоход                   37500 non-null float64\nчисло_кредитов          37500 non-null int64\nповедение_90_дней       37500 non-null int64\nнедвижимость            37500 non-null int64\nповедение_60-89_дней    37500 non-null int64\nсемья                   37500 non-null int64\nfeature_1               37500 non-null bool\nfeature_2               37500 non-null bool\nfeature_6               37500 non-null bool\nfeature_7               37500 non-null bool\nfeature_8               37500 non-null bool\nfeature_9               37500 non-null bool\nfeature_10              37500 non-null bool\nfeature_new             37500 non-null float64\ndtypes: bool(7), float64(4), int64(7)\nmemory usage: 3.4 MB\n"
     ]
    }
   ],
   "source": [
    "test_with_new_feature1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None,\n            criterion='entropy', max_depth=11, max_features=3,\n            max_leaf_nodes=None, min_impurity_decrease=1e-05,\n            min_impurity_split=4e-05, min_samples_leaf=29,\n            min_samples_split=159, min_weight_fraction_leaf=5e-05,\n            n_estimators=125, n_jobs=1, oob_score=False, random_state=20,\n            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forest_last = RandomForestClassifier(n_estimators=125, criterion= 'entropy', min_impurity_decrease=0.00001,\n",
    " min_weight_fraction_leaf = 0.00005,\n",
    " min_impurity_split = 0.00004,\n",
    " max_depth= 11,\n",
    " max_features= 3,\n",
    " #class_weight = 'balanced',\n",
    " min_samples_leaf= 29,\n",
    " min_samples_split= 159,\n",
    " oob_score= True,\n",
    " bootstrap=False,\n",
    " random_state = 20)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, y, train_size = 0.8, random_state=20)\n",
    "\n",
    "rand_forest_last.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc=0.8675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcParams['figure.figsize'] = 8, 5\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate (recall)\")\n",
    "#fpr9, tpr9, _= roc_curve(y_train, pipeline.predict_proba(X_train)[:, 1] )\n",
    "auc9 = roc_auc_score(y_test, rand_forest_last.predict_proba(X_test)[:, 1])\n",
    "#plt.plot(fpr9, tpr9, label=(\"auc=%.4f\" % auc9), linewidth=2, color='#990000')\n",
    "#plt.legend(loc=\"best\")\n",
    "#auc=0.8653 // 2, interaction = True\n",
    "print(\"auc=%.4f\" % auc9)\n",
    "#auc=0.8689"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logreg_pipeline_prediction = rand_forest_last.predict_proba(test)[:, 1]\n",
    "pd.DataFrame({'id' : np.arange(37500), 'a' : model_logreg_pipeline_prediction}).to_csv('/home/paniquex/PycharmProjects/IML_homeworks/credit_scoring/solution_random_forest_with_grid_last.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
